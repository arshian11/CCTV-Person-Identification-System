# -*- coding: utf-8 -*-
"""Untitled18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jyFt7k_XxS9SUXcKFKR5AbjgSBbXyxqy
"""

!pip install ultralytics easyocr opencv-python pymongo

from ultralytics import YOLO
import cv2
import numpy as np
import easyocr
import os

OBJECT_MODEL_PATH = "yolov8n.pt"   # COCO model for person + vehicles
PLATE_MODEL_PATH = "license_plate_detection.pt"       # your working license plate detector
OUTPUT_DIR = "output"

def ensure_dir(path):
    if not os.path.exists(path):
        os.makedirs(path)


def center(box):
    x1, y1, x2, y2 = map(int, box)
    return ( (x1 + x2) // 2, (y1 + y2) // 2 )


def distance(c1, c2):
    return abs(c1[0] - c2[0]) + abs(c1[1] - c2[1])

def enhance_plate(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray = cv2.resize(gray, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
    blur = cv2.GaussianBlur(gray, (3, 3), 0)
    sharpen = cv2.addWeighted(gray, 1.5, blur, -0.5, 0)
    return sharpen

print("[INFO] Loading models...")
object_model = YOLO(OBJECT_MODEL_PATH)
plate_model = YOLO(PLATE_MODEL_PATH)
reader = easyocr.Reader(['en'])

def process_image(image_path):
    ensure_dir(OUTPUT_DIR)

    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Could not read image: {image_path}")

    h, w = img.shape[:2]

    det = object_model(img, imgsz=960)[0]

    persons = []           # list of boxes
    vehicles = []          # list of boxes
    vehicle_labels = []    # corresponding labels

    for box in det.boxes:
        cls = int(box.cls[0])
        label = object_model.names[cls]
        bb = box.xyxy[0].tolist()

        if label == "person":
            persons.append(bb)
        elif label in ["car", "motorbike", "motorcycle", "bus", "truck"]:
            vehicles.append(bb)
            vehicle_labels.append(label)

    plate_det = plate_model(img, imgsz=1280)[0]
    plates = [b.xyxy[0].tolist() for b in plate_det.boxes]


    plate_entries = []  # list of dicts: { "box": box, "text": text }

    for idx, pbox in enumerate(plates):
        x1, y1, x2, y2 = map(int, pbox)
        plate_crop = img[y1:y2, x1:x2]

        if plate_crop.size == 0:
            continue

        enhanced = enhance_plate(plate_crop)
        ocr_result = reader.readtext(enhanced, detail=0)
        text = ocr_result[0] if len(ocr_result) > 0 else ""

        # Optionally save plate crop
        plate_path = os.path.join(OUTPUT_DIR, f"plate_{idx}.jpg")
        cv2.imwrite(plate_path, plate_crop)

        plate_entries.append({
            "box": pbox,
            "text": text,
            "image_path": plate_path
        })

    associations = []   # final results

    person_id = 0
    for pbox in persons:
        pc = center(pbox)

        # Find nearest vehicle to this person
        best_v = None
        best_v_label = None
        best_v_dist = 1e9
        best_v_idx = -1

        for i, vbox in enumerate(vehicles):
            vc = center(vbox)
            d = distance(pc, vc)
            if d < best_v_dist:
                best_v_dist = d
                best_v = vbox
                best_v_label = vehicle_labels[i]
                best_v_idx = i

        if best_v is None:
            continue  # no vehicle found for this person

        # Find nearest plate to that vehicle
        vc = center(best_v)
        best_plate = None
        best_plate_text = ""
        best_plate_dist = 1e9
        best_plate_img_path = None

        for p_entry in plate_entries:
            plc = center(p_entry["box"])
            d = distance(vc, plc)
            if d < best_plate_dist:
                best_plate_dist = d
                best_plate = p_entry["box"]
                best_plate_text = p_entry["text"]
                best_plate_img_path = p_entry["image_path"]


        x1, y1, x2, y2 = map(int, pbox)
        person_crop = img[y1:y2, x1:x2]
        person_img_path = os.path.join(OUTPUT_DIR, f"person_{person_id}.jpg")
        if person_crop.size != 0:
            cv2.imwrite(person_img_path, person_crop)
        else:
            person_img_path = None

        vx1, vy1, vx2, vy2 = map(int, best_v)
        vehicle_crop = img[vy1:vy2, vx1:vx2]
        vehicle_img_path = os.path.join(OUTPUT_DIR, f"vehicle_{person_id}.jpg")
        if vehicle_crop.size != 0:
            cv2.imwrite(vehicle_img_path, vehicle_crop)
        else:
            vehicle_img_path = None

        associations.append({
            "person_id": person_id,
            "person_box": pbox,
            "person_image": person_img_path,

            "vehicle_box": best_v,
            "vehicle_type": best_v_label,
            "vehicle_image": vehicle_img_path,

            "plate_box": best_plate,
            "plate_number": best_plate_text,
            "plate_image": best_plate_img_path
        })

        person_id += 1

    return associations

test_image = "cars.jpg"   # change to your image path
results = process_image(test_image)
print("\n=== ASSOCIATIONS ===")
for r in results:
  print({
            "person_id": r["person_id"],
            "vehicle_type": r["vehicle_type"],
            "plate_number": r["plate_number"],
            "person_image": r["person_image"],
            "vehicle_image": r["vehicle_image"],
            "plate_image": r["plate_image"],
        })

#------------------- attaching multiple vehicles to their corresponding vehicles

# Load models
vehicle_model = YOLO("yolov8n.pt")     # detects car, motorcycle
plate_model   = YOLO("license_plate_detection.pt")        # your Indian ANPR model
reader = easyocr.Reader(['en'])

def center(box):
    x1, y1, x2, y2 = map(int, box)
    return ((x1 + x2)//2, (y1 + y2)//2)

def distance(c1, c2):
    return abs(c1[0] - c2[0]) + abs(c1[1] - c2[1])

def iou(a, b):
    xA = max(a[0], b[0])
    yA = max(a[1], b[1])
    xB = min(a[2], b[2])
    yB = min(a[3], b[3])

    interW = max(0, xB - xA)
    interH = max(0, yB - yA)
    interArea = interW * interH

    if interArea == 0:
        return 0

    areaA = (a[2]-a[0]) * (a[3]-a[1])
    areaB = (b[2]-b[0]) * (b[3]-b[1])
    return interArea / float(areaA + areaB - interArea)

def match_vehicle_plate(image_path):

    img = cv2.imread(image_path)

    # 1) Detect vehicles
    det = vehicle_model(img, imgsz=960)[0]

    vehicles = []
    labels   = []

    for box in det.boxes:
        cls = int(box.cls[0])
        label = vehicle_model.names[cls]
        bb = box.xyxy[0].tolist()

        if label in ["car", "motorbike", "motorcycle"]:
            vehicles.append(bb)
            labels.append(label)

    # 2) Detect plates
    plate_det = plate_model(img, imgsz=1280)[0]
    plate_boxes = [b.xyxy[0].tolist() for b in plate_det.boxes]

    # OCR all plates
    plates = []
    for pb in plate_boxes:
        x1, y1, x2, y2 = map(int, pb)
        crop = img[y1:y2, x1:x2]

        ocr = reader.readtext(crop, detail=0)
        text = ocr[0] if len(ocr) else ""

        plates.append({
            "box": pb,
            "text": text
        })

    # 3) Attach correct plate to each vehicle
    output = []

    for vbox, label in zip(vehicles, labels):

        best_iou = -1
        best_plate = None

        # FIRST PRIORITY: IoU
        for p in plates:
            score = iou(vbox, p["box"])
            if score > best_iou:
                best_iou = score
                best_plate = p

        # FALLBACK: distance if IoU = 0
        if best_iou == 0:
            vc = center(vbox)
            best_dist = 999999

            for p in plates:
                pc = center(p["box"])
                d = distance(vc, pc)
                if d < best_dist:
                    best_dist = d
                    best_plate = p

        output.append({
            "vehicle_type": label,
            "plate_number": best_plate["text"]
        })

    return output

result = match_vehicle_plate("cars.jpg")
print(result)

